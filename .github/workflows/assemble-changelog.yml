name: Assemble Changelog

on:
  push:
    branches: [ main ]
  workflow_dispatch:
  schedule:
    - cron: '15 5 * * *'

permissions:
  contents: write

jobs:
  changelog:
    runs-on: ubuntu-latest
    steps:
      - name: Checkout
        uses: actions/checkout@v4
        with:
          fetch-depth: 0

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.x'

      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install --upgrade openai

      - name: Assemble changelog
        env:
          OPENAI_API_KEY: ${{ secrets.OPENAI_KEY }}
          DEBUG: ${{ vars.CHANGELOG_DEBUG }}
          PYTHONUNBUFFERED: "1"
        shell: bash
        run: |
          python3 -u - <<'PY'
          import os, subprocess, re, datetime, textwrap, sys
          from pathlib import Path

          REPO = Path('.')
          CHANGES_DIR = REPO / 'docs' / 'about' / 'changes'
          WHATS_NEW = REPO / 'docs' / 'about' / 'whats-new.md'
          CHANGES_DIR.mkdir(parents=True, exist_ok=True)

          # ---------- Logging ----------
          DEBUG = os.environ.get('DEBUG', '').lower() in ('1', 'true', 'yes', 'on')
          def log(msg: str, level: str = "INFO"):
              ts = datetime.datetime.now(datetime.timezone.utc).strftime("%Y-%m-%dT%H:%M:%SZ")
              print(f"[{ts}] [{level}] {msg}", flush=True)
          def dlog(msg: str):
              if DEBUG:
                  log(msg, "DEBUG")

          # Ensure shell helper 'sh' exists (fallback)
          if 'sh' not in globals():
              def sh(cmd: str) -> str:
                  return subprocess.check_output(cmd, shell=True, text=True)
              dlog("Fallback 'sh' helper definiert.")

          log("Starte Changelog-Lauf…")

          # ---------- MDX Sanitizing helpers ----------
          import html
          def sanitize_for_mdx(md: str):
              """Escape MDX-hostile constructs in the body (not front matter). Returns (new_text, num_replacements)."""
              reps = 0
              # Rule A: Any "<" that does NOT start a valid HTML/MDX tag/comment/closing-tag becomes &lt;
              # Valid starters: letters, '/', '!', '?', '$', '_'
              md, nA = re.subn(r'<(?![A-Za-z\\/!\\?_\\$])', '&lt;', md)
              reps += nA
              # Rule B: Explicitly cover "<" directly before a digit (defensive; overlapped by A but kept for clarity)
              md, nB = re.subn(r'<(?=\\d)', '&lt;', md)
              reps += nB
              # Rule C: Lines that begin with a date like 2025-08-09 immediately after "<" (just in case of missed combos)
              md, nC = re.subn(r'<(?=\\d{4}-\\d{2}-\\d{2})', '&lt;', md)
              reps += nC
              # Rule D: Prevent accidental JSX from constructs like "< text" at line starts
              md, nD = re.subn(r'^(\\s*)<\\s+', r'\\1&lt; ', md, flags=re.M)
              reps += nD
              # Rule E: Balance lone ">" that are not part of tags by escaping if preceded by whitespace+digits (rare)
              md, nE = re.subn(r'(?<=\\s\\d)>', '&gt;', md)
              reps += nE
              return md, reps
          
          def split_front_matter(text: str):
              """Return (front_matter_text, body_text) if front matter is present at top, else (None, text)."""
              lines = text.splitlines(True)
              i = 0
              while i < len(lines) and lines[i].strip() == '':
                  i += 1
              if i >= len(lines) or lines[i].strip() != '---':
                  return None, text
              start = i
              i += 1
              while i < len(lines) and lines[i].strip() != '---':
                  i += 1
              if i >= len(lines):
                  # no closing fence
                  return None, text
              end = i  # line with closing ---
              fm = ''.join(lines[:end+1])
              body = ''.join(lines[end+1:])
              return fm, body

          def normalize_front_matter(text: str) -> str:
              text = text.replace('\\n', '\n')
              # Remove BOM/NUL and normalize front matter delimiters + indentation
              text = text.replace('\ufeff', '').replace('\x00', '')
              lines = text.splitlines(True)

              # find opening '---'
              i = 0
              while i < len(lines) and lines[i].strip() == '':
                  i += 1
              if not (i < len(lines) and lines[i].lstrip().startswith('---')):
                  return ''.join(lines)

              lines[i] = '---\n'
              i += 1
              while i < len(lines):
                  if lines[i].lstrip().startswith('---'):
                      lines[i] = '---\n'
                      i += 1
                      break
                  lines[i] = lines[i].lstrip(' \t')
                  i += 1

              if i < len(lines) and lines[i].strip() != '':
                  lines.insert(i, '\n')
              elif i >= len(lines):
                  lines.append('\n')
              # Ensure a blank line after closing front matter, then return
              return ''.join(lines)

          # Repair existing change files
          repaired = 0
          for p in CHANGES_DIR.glob('*.md'):
              try:
                  raw = p.read_text(encoding='utf-8')
                  fixed = normalize_front_matter(raw)
                  # Sanitize body for MDX safety
                  fm, body = split_front_matter(fixed)
                  if fm is None:
                      # No front matter detected; sanitize whole text as a fallback
                      body_sanitized, s_count = sanitize_for_mdx(fixed)
                      new_text = body_sanitized
                  else:
                      body_sanitized, s_count = sanitize_for_mdx(body)
                      new_text = (fm + body_sanitized)
                  changed = (new_text != raw)
                  if changed:
                      p.write_text(new_text, encoding='utf-8')
                      repaired += 1
                      dlog(f"Front-Matter/MDX repariert: {p} (Sanitizations: {s_count})")
              except Exception:
                  pass

          log(f"{repaired} bestehende Dateien repariert.")

          def existing_shas() -> set[str]:
              shas = set()
              for p in CHANGES_DIR.glob('*.md'):
                  m = re.fullmatch(r'(?:\\d{4}-\\d{2}-\\d{2}-)?([0-9a-f]{40})\\.md', p.name)
                  if m:
                      shas.add(m.group(1))
                      continue
                  try:
                      txt = p.read_text(encoding='utf-8')
                      m2 = re.search(r'^sha:\\s*\"?([0-9a-f]{40})\"?\\s*$', txt, flags=re.M)
                      if m2:
                          shas.add(m2.group(1))
                  except Exception:
                      pass
              return shas

          def get_commits():
              fmt = '%H\\x1f%an\\x1f%ad\\x1f%s'
              out = sh(f"git log --date=iso --pretty=format:'{fmt}'")
              commits = []
              for line in out.splitlines():
                  sha, author, adate, subject = line.split('\\x1f')
                  commits.append({'sha': sha, 'author': author, 'date': adate, 'subject': subject})
              return commits

          def get_commit_files(sha: str):
              out = sh(f"git diff-tree -m --no-commit-id --name-only -r {sha}")
              return [ln.strip() for ln in out.splitlines() if ln.strip()]

          def get_diff(sha: str) -> str:
              try:
                  diff = sh(f"git show -m {sha} --pretty=format: --unified=3")
              except subprocess.CalledProcessError:
                  diff = ''
              return diff[:50000]

          def is_merge_commit(sha: str) -> bool:
              try:
                  parents = sh(f"git show -s --format=%P {sha}").split()
                  return len(parents) >= 2
              except Exception:
                  return False

          # ---------- OpenAI ----------
          from openai import OpenAI
          client = OpenAI()

          SYSTEM = (
              "You are a technical release note writer. For a given Git commit + diff, write a concise, plain-English summary in Markdown.\n"
              "- Tone: neutral, informative; avoid marketing fluff and emojis.\n"
              "- Do NOT include code diffs.\n"
              "- Prefer 5–10 bullet points, short and concrete.\n"
              "- Explain WHAT changed and WHY it matters (end with one line starting with 'Why it matters:').\n"
              "- Use British spelling or neutral English.\n"
          )

          TITLE_SYSTEM = (
              "You create ultra-short, informative English titles for commit-level change logs.\n"
              "- 3–8 words, no ending period, no emojis.\n"
              "- Capture the essence of the change, not the process (e.g., 'Improve navigation sidebar collapse').\n"
              "- Avoid generic words like 'update', 'changes', 'stuff'.\n"
          )

          def make_short_title(subject: str, files: list[str], diff_snippet: str) -> str:
              seed = "Files: " + ", ".join(files[:12]) if files else "Files: n/a"
              prompt = (
                  "Write a 3–8 word English title that summarises the commit.\n"
                  "Be specific. Avoid generic words. No emojis, no trailing dot.\n\n"
                  f"Subject: {subject}\n"
                  f"{seed}\n"
                  "Diff (truncated, for context only):\n---\n"
                  f"{diff_snippet[:2000]}\n---\n"
              )
              t = call_model(TITLE_SYSTEM, prompt)
              # one line, strip Markdown code fences just in case
              return t.strip().strip("#").strip()

          def call_model(system: str, user: str) -> str:
              resp = client.chat.completions.create(
                  model="gpt-4o-mini",
                  temperature=0.4,
                  messages=[{"role":"system","content":system},{"role":"user","content":user}],
              )
              return resp.choices[0].message.content.strip()

          def build_commit_markdown(sha, author, date, subject, body_md, merge: bool, title_line: str) -> str:
              sanitized_subject = subject.replace('"', '\\"')
              lines = []
              lines.append('---')
              lines.append(f'sha: "{sha}"')
              lines.append(f'author: "{author}"')
              lines.append(f'date: "{date}"')
              lines.append(f'subject: "{sanitized_subject}"')
              lines.append(f'merge: {"true" if merge else "false"}')
              lines.append('---')
              lines.append('')
              # H1 title
              lines.append(f"# {title_line}")
              lines.append('')
              # Body
              lines.append(body_md.strip())
              lines.append('')
              # GitHub link
              lines.append(f"[View this commit on GitHub](https://github.com/TheTrustedAdvisor/FabricAdoptionFramework/commit/{sha})")
              lines.append('')
              return "\n".join(lines)

          created = []
          existing = existing_shas()
          log(f"{len(existing)} bereits vorhandene Commit-Dateien erkannt.")
          commits = get_commits()
          log(f"{len(commits)} Commits im Repository gefunden.")
          skipped_existing = 0
          skipped_workflow_only = 0
          processed = 0
          for idx, c in enumerate(commits, 1):
              sha = c['sha']
              subject = c['subject']
              log(f"[{idx}/{len(commits)}] Prüfe Commit {sha[:7]} – {subject}")
              if sha in existing:
                  skipped_existing += 1
                  dlog(f"Übersprungen (bereits vorhanden): {sha[:7]}")
                  continue
              files = get_commit_files(sha)
              if files and all(f.startswith('.github/') for f in files):
                  skipped_workflow_only += 1
                  dlog(f"Übersprungen (nur Workflow-Dateien): {sha[:7]}")
                  continue
              diff = get_diff(sha)
              dlog(f"Diff-Länge: {len(diff)} Zeichen")
              # Build dynamic English title: "Changes – YYYY-MM-DD: <short title> (<shortsha>)"
              date_prefix = c['date'].split(' ')[0]
              short_title = make_short_title(subject, files, diff)
              title_line = f"Changes – {date_prefix}: {short_title} ({sha[:7]})"
              user_prompt = textwrap.dedent(f"""
              Commit: {sha}
              Autor: {c['author']}
              Datum: {c['date']}
              Betroffene Dateien (Auszug): {', '.join(files[:20]) if files else 'k.A.'}

              Commit-Betreff: {subject}

              Hier der technische Diff (nur fuer dich zur Analyse, **nicht** als Ausgabe uebernehmen):
              ---
              {diff}
              ---

              Aufgabe: Schreibe eine leicht verstaendliche, umgangssprachliche Zusammenfassung der Aenderungen als Markdown.
              Anforderungen:
              - Kein DIFF, keine Code-Blöcke mit +/-
              - Max. 10 Bulletpoints, klar und praegnant
              - Wenn Docs betroffen sind, erwaehne relevante Themenbereiche
              - Schließe mit einem kurzen Satz: "Warum das wichtig ist"
              """)
              dlog("Calling OpenAI for English body…")
              # Force English in the user prompt.
              user_prompt = "Write the following summary in ENGLISH.\n\n" + user_prompt
              body_md = call_model(SYSTEM, user_prompt)
              body_md, s_new = sanitize_for_mdx(body_md)
              dlog(f"MDX sanitize for new file: {s_new} replacements")
              filename = f"{date_prefix}-{sha}.md"
              out_path = CHANGES_DIR / filename
              merge_flag = is_merge_commit(sha)
              out_path.write_text(
                  build_commit_markdown(sha, c['author'], c['date'], subject, body_md, merge_flag, title_line),
                  encoding='utf-8'
              )
              created.append(out_path)
              processed += 1
              log(f"✅ Datei erstellt: {out_path.name}")

          # Build what's-new from latest 20 entries
          def read_entry(p: Path) -> dict:
              txt = p.read_text(encoding='utf-8')
              msha = re.search(r'^sha:\\s*([0-9a-f]{40})$', txt, flags=re.M)
              msub = re.search(r'^subject:\\s*\"?(.*?)\"?$', txt, flags=re.M)
              mdate = re.search(r'^date:\\s*(.*)$', txt, flags=re.M)
              mhead = re.search(r'^#\\s+(.+)$', txt, flags=re.M)
              teaser = mhead.group(1).strip() if mhead else (msub.group(1) if msub else '')
              return {'sha': msha.group(1) if msha else p.stem,
                      'subject': msub.group(1) if msub else '',
                      'date': mdate.group(1) if mdate else '',
                      'teaser': teaser,
                      'path': p}

          log("Erzeuge 'whats-new.md'…")
          all_change_files = sorted(CHANGES_DIR.glob('*.md'))
          if all_change_files:
              order_map = {c['sha']: i for i, c in enumerate(commits)}
              def sort_key(p: Path):
                  m = re.fullmatch(r'(?:\\d{4}-\\d{2}-\\d{2}-)?([0-9a-f]{40})', p.stem)
                  key_sha = m.group(1) if m else p.stem
                  return order_map.get(key_sha, 10**9)
              ordered = sorted(all_change_files, key=sort_key)
              ordered.reverse()
              latest = [read_entry(p) for p in ordered[:60]]  # take up to ~60 recent entries

              # Group by year-month
              by_month = {}
              for e in latest:
                  # parse YYYY-MM from date (fallback to filename prefix if needed)
                  m = re.search(r'^(\\d{4})-(\\d{2})', e['date'])
                  if not m:
                      m = re.search(r'^(\\d{4})-(\\d{2})', e['path'].name)
                  ym = f"{m.group(1)}-{m.group(2)}" if m else "unknown"
                  by_month.setdefault(ym, []).append(e)

              # Prepare a compact feed for the model
              # Use title (H1) from the file if present; else subject as fallback.
              def extract_title(e: dict) -> str:
                  try:
                      txt = e['path'].read_text(encoding='utf-8')
                  except Exception:
                      return e.get('subject') or ''
                  mh1 = re.search(r'^#\\s+(.+)$', txt, flags=re.M)
                  return mh1.group(1).strip() if mh1 else (e.get('subject') or '')

              # Build an input string grouped by month, newest month first
              months_sorted = sorted(by_month.keys(), reverse=True)
              grouped_input_parts = []
              for ym in months_sorted:
                  items = by_month[ym][:12]  # cap per month to avoid token bloat
                  titles = [f"- {extract_title(e)}" for e in items if extract_title(e)]
                  if not titles:
                      continue
                  grouped_input_parts.append(f"{ym}\\n" + "\\n".join(titles))
              grouped_input = "\\n\\n".join(grouped_input_parts)

              wn_prompt = textwrap.dedent(f"""
              Create a concise **What's new** page in English for a Docusaurus docs site.

              Requirements:
              - Start with: "# What's new"
              - Then list sections by month (most recent first), using "## Month YYYY" (e.g., "## August 2025").
              - Under each month, add 3–8 bullet points summarising the most important changes for that month.
              - Use plain text bullets (no emojis, no code diffs).
              - Avoid generic statements; be specific to the listed items.
              - Do not invent features; only summarise what is implied by the items.
              - Keep it succinct.

              Source items grouped by YYYY-MM (newest first):
              ---
              {grouped_input}
              ---
              """)

              wn_md = call_model(
                  "You are a precise release highlight writer. Use clear English and monthly grouping.",
                  wn_prompt
              )

              WHATS_NEW.parent.mkdir(parents=True, exist_ok=True)
              header = f"<!-- Auto-generated by assemble-changelog.yml on {datetime.datetime.now(datetime.timezone.utc).isoformat()} -->\\n"
              WHATS_NEW.write_text(header + "\\n" + wn_md.strip() + "\\n", encoding='utf-8')
              log(f"'whats-new.md' updated (months: {len(months_sorted)})")

          log(f"FERTIG. Neue Dateien: {len(created)} | Repariert: {repaired} | Übersprungen (vorhanden): {skipped_existing} | Übersprungen (.github): {skipped_workflow_only} | Gesamt-Commits: {len(commits)}")
          log("Changelog-Lauf abgeschlossen.")
          PY

      - name: Commit and push changes
        shell: bash
        run: |
          bash -euo pipefail <<'BASH'
          set -x
          git config user.name "github-actions[bot]"
          git config user.email "41898282+github-actions[bot]@users.noreply.github.com"
          git add -A docs/about/changes docs/about/whats-new.md || true
          if git diff --staged --quiet; then
            echo "No changes to commit."
          else
            git commit -m "docs(changelog): update whats-new and per-commit entries [skip ci]"
            git push
          fi
          BASH